{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_CmXeQ_W18B",
        "outputId": "b0f48aa5-89ef-4247-8adb-668cf315d1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Figures saved to: figures\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==========================================================\n",
        "# Settings\n",
        "# ==========================================================\n",
        "SEED = 7\n",
        "np.random.seed(SEED)\n",
        "\n",
        "OUTDIR = \"figures\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# Windowing\n",
        "FS = 250                    # sampling rate (Hz) for synthetic demonstration\n",
        "N = 256                     # must be power of 2\n",
        "HOP = 64                    # overlap step\n",
        "LAMBDA = 0.10               # shrinkage intensity\n",
        "ALPHA = 0.01                # false alarm target (empirical threshold)\n",
        "\n",
        "# ==========================================================\n",
        "# Walsh-Hadamard (fast) and Sequency ordering (correct)\n",
        "# ==========================================================\n",
        "def hadamard_matrix(n: int) -> np.ndarray:\n",
        "    \"\"\"Construct Hadamard matrix H_n with Sylvester recursion.\"\"\"\n",
        "    assert (n & (n - 1)) == 0 and n > 0\n",
        "    H = np.array([[1.0]])\n",
        "    while H.shape[0] < n:\n",
        "        H = np.block([[H, H], [H, -H]])\n",
        "    return H\n",
        "\n",
        "def wht_matrix(n: int) -> np.ndarray:\n",
        "    \"\"\"Normalized Walsh-Hadamard transform matrix W_n = H_n / sqrt(n).\"\"\"\n",
        "    H = hadamard_matrix(n)\n",
        "    return H / np.sqrt(n)\n",
        "\n",
        "def sequency_of_row(w: np.ndarray) -> int:\n",
        "    \"\"\"Number of sign changes in a +-1 row vector.\"\"\"\n",
        "    return int(np.sum(np.abs(np.diff(w)) > 0))\n",
        "\n",
        "def sequency_permutation(W: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Return permutation indices that sort rows by sequency (ascending),\n",
        "    breaking ties by original index.\n",
        "    \"\"\"\n",
        "    H = np.sign(W * np.sqrt(W.shape[0]))  # recover +-1 pattern\n",
        "    seq = np.array([sequency_of_row(H[i, :]) for i in range(H.shape[0])])\n",
        "    perm = np.lexsort((np.arange(W.shape[0]), seq))  # stable deterministic\n",
        "    return perm\n",
        "\n",
        "def wht_sequency(x: np.ndarray, W: np.ndarray, perm: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Sequency-ordered Walsh coefficients.\"\"\"\n",
        "    c_nat = W @ x\n",
        "    return c_nat[perm]\n",
        "\n",
        "def iwht_sequency(c_seq: np.ndarray, W: np.ndarray, perm: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Inverse transform from sequency ordered coefficients.\"\"\"\n",
        "    # invert permutation\n",
        "    inv = np.empty_like(perm)\n",
        "    inv[perm] = np.arange(len(perm))\n",
        "    c_nat = c_seq[inv]\n",
        "    return W.T @ c_nat\n",
        "\n",
        "# Precompute\n",
        "W = wht_matrix(N)\n",
        "perm = sequency_permutation(W)\n",
        "\n",
        "# ==========================================================\n",
        "# Synthetic ECG generator (open, reproducible demonstration)\n",
        "# ==========================================================\n",
        "def synthetic_ecg(t: np.ndarray, hr_bpm: float = 70.0, noise: float = 0.01) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Simple synthetic ECG-like waveform as sum of Gaussian pulses per beat.\n",
        "    This is not a physiological model; it is a reproducible signal generator.\n",
        "    \"\"\"\n",
        "    rr = 60.0 / hr_bpm\n",
        "    x = np.zeros_like(t)\n",
        "    beat_times = np.arange(t[0] + 0.2, t[-1] - 0.2, rr)\n",
        "\n",
        "    # P, Q, R, S, T waves (rough)\n",
        "    for bt in beat_times:\n",
        "        x += 0.08 * np.exp(-0.5 * ((t - (bt - 0.20)) / 0.03) ** 2)   # P\n",
        "        x += -0.12 * np.exp(-0.5 * ((t - (bt - 0.03)) / 0.01) ** 2) # Q\n",
        "        x += 1.00 * np.exp(-0.5 * ((t - bt) / 0.012) ** 2)          # R\n",
        "        x += -0.25 * np.exp(-0.5 * ((t - (bt + 0.02)) / 0.012) ** 2)# S\n",
        "        x += 0.30 * np.exp(-0.5 * ((t - (bt + 0.25)) / 0.05) ** 2)  # T\n",
        "\n",
        "    x += noise * np.random.randn(len(t))\n",
        "    return x\n",
        "\n",
        "def inject_anomaly(x: np.ndarray, fs: int, start_s: float, end_s: float, kind: str = \"st_shift\") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Inject an interpretable anomaly into ECG segment.\n",
        "    - st_shift: baseline shift in a local interval\n",
        "    - spike: impulsive artifact\n",
        "    - widen_qrs: local convolution widening\n",
        "    \"\"\"\n",
        "    y = x.copy()\n",
        "    a = int(start_s * fs)\n",
        "    b = int(end_s * fs)\n",
        "    a = max(a, 0); b = min(b, len(y))\n",
        "\n",
        "    if kind == \"st_shift\":\n",
        "        y[a:b] += 0.15\n",
        "    elif kind == \"spike\":\n",
        "        idx = (a + b) // 2\n",
        "        y[idx:idx+3] += 0.8\n",
        "    elif kind == \"widen_qrs\":\n",
        "        # mild smoothing in the segment\n",
        "        k = np.array([0.2, 0.6, 0.2])\n",
        "        seg = y[a:b]\n",
        "        if len(seg) > 3:\n",
        "            y[a:b] = np.convolve(seg, k, mode=\"same\")\n",
        "    else:\n",
        "        raise ValueError(\"Unknown anomaly kind.\")\n",
        "    return y\n",
        "\n",
        "# ==========================================================\n",
        "# Windowing utilities\n",
        "# ==========================================================\n",
        "def frame_signal(x: np.ndarray, n: int, hop: int) -> np.ndarray:\n",
        "    \"\"\"Return frames shape (T, n).\"\"\"\n",
        "    T = 1 + (len(x) - n) // hop\n",
        "    frames = np.stack([x[i*hop:i*hop+n] for i in range(T)], axis=0)\n",
        "    return frames\n",
        "\n",
        "def overlap_add(values_per_frame: np.ndarray, n: int, hop: int, out_len: int, agg: str = \"max\") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Aggregate frame-level per-sample quantities back to full length.\n",
        "    values_per_frame: shape (T, n)\n",
        "    \"\"\"\n",
        "    T = values_per_frame.shape[0]\n",
        "    accum = np.zeros(out_len)\n",
        "    count = np.zeros(out_len)\n",
        "\n",
        "    if agg == \"mean\":\n",
        "        for t in range(T):\n",
        "            start = t * hop\n",
        "            end = start + n\n",
        "            accum[start:end] += values_per_frame[t]\n",
        "            count[start:end] += 1.0\n",
        "        return accum / np.maximum(count, 1.0)\n",
        "\n",
        "    if agg == \"max\":\n",
        "        accum[:] = 0.0\n",
        "        for t in range(T):\n",
        "            start = t * hop\n",
        "            end = start + n\n",
        "            accum[start:end] = np.maximum(accum[start:end], values_per_frame[t])\n",
        "        return accum\n",
        "\n",
        "    raise ValueError(\"agg must be 'mean' or 'max'.\")\n",
        "\n",
        "# ==========================================================\n",
        "# Reference estimation and scoring\n",
        "# ==========================================================\n",
        "def shrink_cov(S: np.ndarray, lam: float) -> np.ndarray:\n",
        "    tr = np.trace(S)\n",
        "    n = S.shape[0]\n",
        "    return (1.0 - lam) * S + lam * (tr / n) * np.eye(n)\n",
        "\n",
        "def fit_reference(C: np.ndarray, lam: float) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    C: (L, N) sequency-ordered coeff vectors.\n",
        "    Returns mu, Sigma_lam, inv(Sigma_lam) via Cholesky solve.\n",
        "    \"\"\"\n",
        "    mu = C.mean(axis=0)\n",
        "    X = C - mu\n",
        "    S = (X.T @ X) / max(C.shape[0] - 1, 1)\n",
        "    Sig = shrink_cov(S, lam)\n",
        "    # robust inverse via cholesky\n",
        "    Lc = np.linalg.cholesky(Sig)\n",
        "    # function handle: inv(Sig) @ v = solve(Lc.T, solve(Lc, v))\n",
        "    return mu, Sig, Lc\n",
        "\n",
        "def mahalanobis_sq(c: np.ndarray, mu: np.ndarray, Lc: np.ndarray) -> float:\n",
        "    v = c - mu\n",
        "    y = np.linalg.solve(Lc, v)\n",
        "    return float(y @ y)\n",
        "\n",
        "def standardized_deviation(c: np.ndarray, mu: np.ndarray, Lc: np.ndarray) -> np.ndarray:\n",
        "    v = c - mu\n",
        "    return np.linalg.solve(Lc, v)  # z = Sigma^{-1/2} (c-mu)\n",
        "\n",
        "# ==========================================================\n",
        "# Visualization helpers\n",
        "# ==========================================================\n",
        "def plot_color_coded_ecg(t, x, score, title, path_png):\n",
        "    \"\"\"\n",
        "    Color-coded line: we draw segments colored by score intensity.\n",
        "    \"\"\"\n",
        "    # normalize score to [0,1]\n",
        "    s = score.copy()\n",
        "    s = s - np.min(s)\n",
        "    if np.max(s) > 0:\n",
        "        s = s / np.max(s)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 3))\n",
        "    for i in range(len(x) - 1):\n",
        "        ax.plot(t[i:i+2], x[i:i+2], color=plt.cm.inferno(s[i]), linewidth=1.5)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Time (s)\")\n",
        "    ax.set_ylabel(\"Amplitude\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(path_png, dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "def plot_heatmap(M, title, path_png, xlabel=\"Time frame\", ylabel=\"Sequency index\"):\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    im = ax.imshow(M.T, aspect=\"auto\", origin=\"lower\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(path_png, dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "def plot_score_curve(scores, thr, title, path_png):\n",
        "    fig, ax = plt.subplots(figsize=(8, 3))\n",
        "    ax.plot(scores, linewidth=1.5)\n",
        "    ax.axhline(thr, linestyle=\"--\", linewidth=1.2)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Time frame\")\n",
        "    ax.set_ylabel(r\"$d^2(c_t)$\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(path_png, dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "# ==========================================================\n",
        "# Main demo\n",
        "# ==========================================================\n",
        "def main():\n",
        "    # --- create synthetic healthy and test signals ---\n",
        "    dur = 10.0\n",
        "    t = np.arange(0, dur, 1 / FS)\n",
        "    x_healthy = synthetic_ecg(t, hr_bpm=70, noise=0.01)\n",
        "\n",
        "    x_test = synthetic_ecg(t, hr_bpm=70, noise=0.01)\n",
        "    x_test = inject_anomaly(x_test, FS, start_s=4.0, end_s=5.0, kind=\"st_shift\")\n",
        "    x_test = inject_anomaly(x_test, FS, start_s=7.0, end_s=7.2, kind=\"spike\")\n",
        "\n",
        "    # --- frame signals ---\n",
        "    Fh = frame_signal(x_healthy, N, HOP)\n",
        "    Ft = frame_signal(x_test, N, HOP)\n",
        "\n",
        "    # --- compute sequency-ordered Walsh coeffs ---\n",
        "    Ch = np.stack([wht_sequency(fr, W, perm) for fr in Fh], axis=0)\n",
        "    Ct = np.stack([wht_sequency(fr, W, perm) for fr in Ft], axis=0)\n",
        "\n",
        "    # --- fit reference from healthy coefficients ---\n",
        "    mu, Sig, Lc = fit_reference(Ch, LAMBDA)\n",
        "\n",
        "    # --- compute scores + standardized deviations + time contributions ---\n",
        "    scores = np.array([mahalanobis_sq(Ct[i], mu, Lc) for i in range(Ct.shape[0])])\n",
        "\n",
        "    # empirical threshold from held-out healthy frames (here: second half)\n",
        "    mid = Ch.shape[0] // 2\n",
        "    scores_h = np.array([mahalanobis_sq(Ch[i], mu, Lc) for i in range(mid, Ch.shape[0])])\n",
        "    thr = float(np.quantile(scores_h, 1.0 - ALPHA))\n",
        "\n",
        "    # time contributions per frame: r_t = W^T z_t (but must invert sequency perm back to natural)\n",
        "    Rt = []\n",
        "    for i in range(Ct.shape[0]):\n",
        "        z = standardized_deviation(Ct[i], mu, Lc)  # sequency domain standardized\n",
        "        # map z back through inverse sequency -> natural -> W^T\n",
        "        # We want r = W^T z_nat, where z_nat corresponds to natural ordering coefficients.\n",
        "        # Our z is in sequency-ordered coordinates; convert to natural first.\n",
        "        inv = np.empty_like(perm)\n",
        "        inv[perm] = np.arange(len(perm))\n",
        "        z_nat = z[inv]\n",
        "        r = W.T @ z_nat\n",
        "        Rt.append(np.abs(r))  # magnitude contribution\n",
        "    Rt = np.stack(Rt, axis=0)  # (T, N)\n",
        "\n",
        "    # aggregate |r| back to time axis for color coding\n",
        "    agg_r = overlap_add(Rt, N, HOP, out_len=len(x_test), agg=\"max\")\n",
        "\n",
        "    # --- FIG 1: healthy vs test ---\n",
        "    fig, ax = plt.subplots(figsize=(10, 3))\n",
        "    ax.plot(t, x_healthy, linewidth=1.2, label=\"Healthy (synthetic)\")\n",
        "    ax.plot(t, x_test, linewidth=1.2, label=\"Test (synthetic with anomalies)\", alpha=0.85)\n",
        "    ax.set_title(\"Fig. 1 — Synthetic ECG: Healthy vs. Test with Injected Anomalies\")\n",
        "    ax.set_xlabel(\"Time (s)\")\n",
        "    ax.set_ylabel(\"Amplitude\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(os.path.join(OUTDIR, \"fig1_healthy_vs_test.png\"), dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "    # --- FIG 2: time–sequency heatmap of |coeff| for test ---\n",
        "    heat = np.abs(Ct)\n",
        "    plot_heatmap(heat, \"Fig. 2 — Time–Sequency Map: |Walsh coefficients| (test)\", os.path.join(OUTDIR, \"fig2_heatmap_coeffs_test.png\"))\n",
        "\n",
        "    # --- FIG 3: score curve with threshold ---\n",
        "    plot_score_curve(scores, thr, \"Fig. 3 — Global anomaly score with empirical threshold\", os.path.join(OUTDIR, \"fig3_score_threshold.png\"))\n",
        "\n",
        "    # --- FIG 4: color-coded ECG highlighting (time localization) ---\n",
        "    plot_color_coded_ecg(t, x_test, agg_r, \"Fig. 4 — Time-localized anomaly highlighting (back-projection)\", os.path.join(OUTDIR, \"fig4_color_coded_ecg.png\"))\n",
        "\n",
        "    # --- FIG 5: multi-lead fusion demonstration (synthetic 3 leads) ---\n",
        "    # Create 3 leads as mildly perturbed versions; inject anomaly only in lead 2.\n",
        "    x1 = x_test + 0.005 * np.random.randn(len(x_test))\n",
        "    x2 = inject_anomaly(x_test, FS, 4.0, 5.0, kind=\"st_shift\")  # stronger in lead 2\n",
        "    x3 = x_test + 0.005 * np.random.randn(len(x_test))\n",
        "\n",
        "    def score_signal(xsig):\n",
        "        F = frame_signal(xsig, N, HOP)\n",
        "        C = np.stack([wht_sequency(fr, W, perm) for fr in F], axis=0)\n",
        "        return np.array([mahalanobis_sq(C[i], mu, Lc) for i in range(C.shape[0])])\n",
        "\n",
        "    s1 = score_signal(x1)\n",
        "    s2 = score_signal(x2)\n",
        "    s3 = score_signal(x3)\n",
        "    smax = np.maximum(np.maximum(s1, s2), s3)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 3))\n",
        "    ax.plot(s1, linewidth=1.1, label=\"Lead 1\")\n",
        "    ax.plot(s2, linewidth=1.1, label=\"Lead 2 (focal anomaly)\")\n",
        "    ax.plot(s3, linewidth=1.1, label=\"Lead 3\")\n",
        "    ax.plot(smax, linewidth=1.6, label=\"Max-fusion\", alpha=0.9)\n",
        "    ax.axhline(thr, linestyle=\"--\", linewidth=1.1, label=\"Threshold\")\n",
        "    ax.set_title(\"Fig. 5 — Multi-lead fusion: max emphasizes focal deviations\")\n",
        "    ax.set_xlabel(\"Time frame\")\n",
        "    ax.set_ylabel(r\"$d^2$\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend(ncol=2, fontsize=8)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(os.path.join(OUTDIR, \"fig5_multilead_fusion.png\"), dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "    print(\"Done. Figures saved to:\", OUTDIR)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}
